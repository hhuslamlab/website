@inproceedings{zhou+al.naacl19, 
  title = {Gender Bias in Contextualized Word Embeddings},
  venue = {NAACL},
  year = {2019},
  arXiv = {https://arxiv.org/abs/1904.03310},
  anthology = {https://www.aclweb.org/anthology/N19-1064.pdf},
  author = {Zhao, Jieyu and 
	Wang, Tianlu and 
	Yatskar, Mark and 
	Cotterell, Ryan and 
	Ordonez, Vicente and 
	Chang, Kai-Wei},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month = {June},
  publisher = {Association for Computational Linguistics},
  address = {Minneapolis, Minnesota},
  volume = {1 (Long and Short Papers)},
  pages = {629--634},
  abstract = {In this paper, we quantify, analyze and mitigate gender bias exhibited in ELMo's contextualized word vectors. First, we conduct several intrinsic analyses and find that (1) training data for ELMo contains significantly more male than female entities, (2) the trained ELMo embeddings systematically encode gender information and (3) ELMo unequally encodes gender information about male and female entities. Then, we show that a state-of-the-art coreference system that depends on ELMo inherits its bias and demonstrates significant bias on the WinoBias probing corpus. Finally, we explore two methods to mitigate such gender bias and show that the bias demonstrated on WinoBias can be eliminated.},
  url = {https://www.aclweb.org/anthology/N19-1064.pdf},
}
