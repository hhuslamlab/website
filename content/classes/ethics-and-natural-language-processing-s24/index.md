+++
title = 'Ethics and Natural Language Processing'
subtitle = 'HHU, Summer 2024: [Course catalog](https://lsf.hhu.de/qisserver/rds?state=verpublish&status=init&vmfile=no&publishid=252529&moduleCall=webInfo&publishConfFile=webInfo&publishSubDir=veranstaltung)'
summary = 'Is technology really as innocent and as objective as they are said to be? As machine learning (ML) and Artificial Intelligence (AI) becomes more prominent in our life from speech and voice recognition by Alexa to automatic fake news warnings of social media posts, issues with social bias and fairness in language technology become more pertinent than ever before. Negative impacts that biased ML and AI could have for various social identities such as race, gender and culture. We first introduce the concept of bias in language technology, and the different types of biases  such as racial, gender, cultural biases. To begin to understand the cause of these biases, we will cover the basic underlying structure of some of the technologies such as Automatic Speech Recognition, hate speech detection and word association. To evaluate these biases, we will learn to generate test cases that can be used to evaluate trained systems, and the metrics that are used for measuring bias/fairness. Finally, we will cover the basics of bias mediation and techniques.'

type = "widget_page"
date = "2024-03-24T00:00:00Z"
featured = true 
draft = false
active = true 
show_date = false 
share = false
profile = false

[design.spacing]
  # Customize the section spacing. Order is top, right, bottom, left.
  # padding = ["10px", "0px", "10px", "0"]

+++

