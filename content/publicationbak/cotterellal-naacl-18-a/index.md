---
title: "Are All Languages Equally Hard to Language-Model?"
date: 2018-06-01
publishDate: 2021-08-20T18:07:24.012768Z
authors: ["Ryan Cotterell", "Sabrina J. Mielke", "Jason Eisner", "Brian Roark"]
publication_types: ["1"]
abstract: "For general modeling methods applied to diverse languages, a natural question is: how well should we expect our models to work on languages with differing typological profiles? In this work, we develop an evaluation framework for fair cross-linguistic comparison of language models, using translated text so that all models are asked to predict approximately the same information. We then conduct a study on 21 languages, demonstrating that in some languages, the textual expression of the information is harder to predict with both n-gram and LSTM language models. We show complex inflectional morphology to be a cause of performance differences among languages."
featured: false
publication: "*Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies*"
publication_short: "NAACL"
links:
- name: Anthology
  url: https://www.aclweb.org/anthology/papers/N18-2085.pdf
- name: arXiv
  url: https://arxiv.org/abs/1806.03743
url_pdf: papers/cotterell+al.naacl18a.pdf
---

