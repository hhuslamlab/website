@inproceedings{cotterell+al.conll17,
 title = {CoNLL--SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection in 52 Languages},
 author = {Cotterell, Ryan and 
Kirov, Christo and 
Sylak-Glassman, John and 
Walther, Géraldine and 
Vylomova, Ekaterina and 
Xia, Patrick and 
Faruqui, Manaal and 
Kübler, Sandra and 
Yarowsky, David and 
Eisner, Jason and 
Hulden, Mans},
 booktitle = {Proceedings of the CoNLL SIGMORPHON 2017 Shared Task: Universal Morphological Reinflection},
 month = {August},
 year = {2017},
 address = {Vancouver, Canada},
 publisher = {Association for Computational Linguistics},
 pages = {1--30},
 url = {https://www.aclweb.org/anthology/K17-2001.pdf},
 abstract = {The CoNLL-SIGMORPHON 2017 shared task on supervised morphological generation required systems to be trained and tested in each of 52 typologically diverse languages. In sub-task 1, submitted systems were asked to predict a specific inflected form of a given lemma. In sub-task 2, systems were given a lemma and some of its specific inflected forms, and asked to complete the inflectional paradigm by predicting all of the remaining inflected forms. Both sub-tasks included high, medium, and low-resource conditions. Sub-task 1 received 24 system submissions, while sub-task 2 received 3 system submissions. Following the success of neural sequence-to-sequence models in the SIGMORPHON 2016 shared task, all but one of the submissions included a neural component. The results show that high performance can be achieved with small training datasets, so long as models have appropriate inductive bias or make use of additional unlabeled data or synthetic data. However, different biasing and data augmentation resulted in non-identical sets of inflected forms being predicted correctly, suggesting that there is room for future improvement.}
}

