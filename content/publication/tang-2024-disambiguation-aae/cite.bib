@InProceedings{previlon-etal-2024-leveraging-syntactic,
  author    = {Previlon, Wilermine and Rozet, Alice and Gowda, Jotsna and Dyer, Bill and Tang, Kevin and Moeller, Sarah},
  title     = {Leveraging Syntactic Dependencies in Disambiguation: The Case of {A}frican {A}merican {E}nglish},
  booktitle = {{Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)}},
  year      = {2024},
  editor    = {Calzolari, Nicoletta and Kan, Min-Yen and Hoste, Veronique and Lenci, Alessandro and Sakti, Sakriani and Xue, Nianwen},
  publisher = {ELRA and ICCL},
  month     = may,
  pages     = {10403--10415},
  url       = {https://aclanthology.org/2024.lrec-main.909},
  abstract  = {African American English (AAE) has received recent attention in the field of natural language processing (NLP). Efforts to address bias against AAE in NLP systems tend to focus on lexical differences. When the unique structures of AAE are considered, the solution is often to remove or neutralize the differences. This work leverages knowledge about the unique linguistic structures to improve automatic disambiguation of habitual and non-habitual meanings of {``}be{''} in naturally produced AAE transcribed speech. Both meanings are employed in AAE but examples of Habitual be are rare in already limited AAE data. Generally, representing additional syntactic information improves semantic disambiguation of habituality. Using an ensemble of classical machine learning models with a representation of the unique POS and dependency patterns of Habitual be, we show that integrating syntactic information improves the identification of habitual uses of {``}be{''} by about 65 F1 points over a simple baseline model of n-grams, and as much as 74 points. The success of this approach demonstrates the potential impact when we embrace, rather than neutralize, the structural uniqueness of African American English.},
  address   = {Torino, Italia},
}